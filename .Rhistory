}, data_list, years, SIMPLIFY = FALSE)
df_person <- bind_rows(df_list)  # Concatenate all years
return(df_person)
}
# Define survey years
survey_years <- c(2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024)
# Run function with survey years
df_pers <- fusionPerson(data_list, var_pers, survey_years)
sink("quarto_log3.txt")
# Apply sample selection criteria
df_pers <- df_pers %>%
filter(A_AGE >= 19, A_AGE <= 64, DSAB_VAL == 0, PERLIS %in% c(1, 2, 3))
sink("quarto_log4.txt")
# Merge person and household data sets
df_merged <- inner_join(df_pers, df_hh, by = c("H_SEQ", "H_YEAR"))
# Remove the DSAB_VAL column (disability income indicator)
df_merged <- df_merged %>% select(-DSAB_VAL)
sink("quarto_log5.txt")
# Rename columns for better readability
df_merged <- df_merged %>% rename(
COVERED = NOW_COV,        # Indicator for whether the person currently has health coverage
COV_LY = COV,             # Indicator for whether the person had health coverage last year
HOUSEHOLD_ID = H_SEQ,     # Household sequence number
INCOME = PTOTVAL,         # Total personal income
PRIVATE = NOW_PRIV,   # Indicator for private health insurance coverage
AGE = A_AGE,              # Age of the individual
MEDICAID = NOW_CAID,      # Indicator for Medicaid coverage
YEAR = H_YEAR,            # Survey year
SEX = A_SEX,             # Gender indicator (1 = male, 0 = female)
FIPS = GESTFIPS,      # State indicator (51 = Virginia, 45 = South Carolina)
WORK = A_CLSWKR,          # Employment classification
EDUC = A_HGA,             # Educational attainment
POVERTY_LEVEL = PERLIS,    # Poverty level category
ETHNICITY = PRDTRACE          #Ethnicity of the individual
)
# Create new binary variables for analysis
df_merged <- df_merged %>%
mutate(
VIRGINIA = ifelse(FIPS == 51, 1, 0),  # 1 if the person lives in Virginia, 0 otherwise
COVERED = ifelse(COVERED == 1, 1, 0),     # 1 if covered by any health insurance, 0 otherwise
MEDICAID = ifelse(MEDICAID == 1, 1, 0),   # 1 if covered by Medicaid, 0 otherwise
PRIVATE = ifelse(PRIVATE == 1, 1, 0),    # 1 if covered by private insurance last year, 0 otherwise
MALE = ifelse(SEX == 1, 1, 0),           # 1 if male, 0 if female
SUP2019 = ifelse(YEAR >= 2019, 1, 0),     # 1 if the survey year is 2019 or later, 0 otherwise
HIGHER_BAC = ifelse(EDUC >= 39, 1, 0),         # 1 if education level is master's degree or higher
TREAT = ifelse(SUP2019== 1 & VIRGINIA == 1, 1, 0), # 1 if in Virginia and post-2019 (treated group)
POOREST = ifelse(POVERTY_LEVEL ==2,0,1), # 1 if below 124 percent of the federal poverty level
WHITE = ifelse(ETHNICITY == 1, 1, 0),   # 1 if White
OTHER_ETHNICITY = ifelse(ETHNICITY >= 2, 1, 0) # 1 if not White
)
sink("quarto_log6.txt")
# Output path
output_path_bdd <- file.path(base_dir, "Code", "Output", "bdd_finale.csv")
# Export final data set
write_csv(df_merged, output_path_bdd)
sink("quarto_log7.txt")
# Import the (clean) data set
df <- read_csv(output_path_bdd)
sink("quarto_log8.txt")
####################################################################################################################################
#Descriptive Statistics
#In Virginia
#Number of individuals for each Year in Virginia
treat_2017 = sum(df$YEAR == 2017 & df$VIRGINIA == 1)
treat_2018 = sum(df$YEAR == 2018 & df$VIRGINIA == 1)
treat_2019 = sum(df$YEAR == 2019 & df$VIRGINIA == 1)
treat_2020 = sum(df$YEAR == 2020 & df$VIRGINIA == 1)
treat_2022 = sum(df$YEAR == 2022 & df$VIRGINIA == 1)
treat_2023 = sum(df$YEAR == 2023 & df$VIRGINIA == 1)
treat_2024 = sum(df$YEAR == 2024 & df$VIRGINIA == 1)
treat_2021 = sum(df$YEAR == 2021 & df$VIRGINIA == 1)
#Creation of a list for post-treatment and pre-treatment years
treat_by_year_before <- list(
"2017" = treat_2017,
"2018" = treat_2018)
treat_by_year_after <- list(
"2019" = treat_2019,
"2020" = treat_2020,
"2021" = treat_2021,
"2022" = treat_2022,
"2023" = treat_2023,
"2024" = treat_2024)
#Creation of two functions that compute the minimum, maximum, standard deviation and mean values for post-treatment and pre-treatment periods in Virginia for a specific variable
# First for the pre-treatment period
calculate_cov_virginia_before <- function(data, var_name, treat_values) {
years <- 2017:2018
cov_values <- sapply(years, function(year) {
sum(data$YEAR == year & data$VIRGINIA == 1 & data[[var_name]] == 1) / treat_values[[as.character(year)]]
})
# Mean
mean_cov <- mean(cov_values, na.rm = TRUE)
# Minimum
min_cov <- min(cov_values, na.rm = TRUE)
# Maximum
max_cov <- max(cov_values, na.rm = TRUE)
# Standard deviation
sd_cov <-  sd(cov_values, na.rm = TRUE)
return(list(mean = mean_cov, min = min_cov, max = max_cov, sd = sd_cov))
}
#Secondly for the post-treatment period
calculate_cov_virginia_after <- function(data, var_name, treat_values) {
years <- 2019:2024
cov_values <- sapply(years, function(year) {
sum(data$YEAR == year & data$VIRGINIA == 1 & data[[var_name]] == 1) / treat_values[[as.character(year)]]
})
# Mean
mean_cov <- mean(cov_values, na.rm = TRUE)
# Minimum
min_cov <- min(cov_values, na.rm = TRUE)
# Maximum
max_cov <- max(cov_values, na.rm = TRUE)
# Standard deviation
sd_cov <-  sd(cov_values, na.rm = TRUE)
return(list(mean = mean_cov, min = min_cov, max = max_cov, sd = sd_cov))
}
#Number of people each year in each state
mean = sum(treat_2017, treat_2018)/ 2
mean
min(treat_2017, treat_2018)
max(treat_2017, treat_2018)
sd(c(treat_2017, treat_2018))
mean = sum(treat_2019, treat_2020, treat_2022,
treat_2023, treat_2024, treat_2021 )/ 6
mean
min(treat_2019, treat_2020, treat_2022,
treat_2023, treat_2024, treat_2021 )
max(treat_2019, treat_2020, treat_2022,
treat_2023, treat_2024, treat_2021 )
sd(c(treat_2019, treat_2020, treat_2022,
treat_2023, treat_2024, treat_2021 ))
#Computation of the descriptive statistics for each variable, post and pre-treatment
calculate_cov_virginia_before(df, "COVERED", treat_by_year_before)
calculate_cov_virginia_before(df, "MALE", treat_by_year_before)
calculate_cov_virginia_before(df, "HIGHER_BAC", treat_by_year_before)
calculate_cov_virginia_before(df, "PRIVATE", treat_by_year_before)
calculate_cov_virginia_before(df, "POOREST", treat_by_year_before)
calculate_cov_virginia_before(df, "WHITE", treat_by_year_before)
calculate_cov_virginia_before(df, "OTHER_ETHNICITY", treat_by_year_before)
calculate_cov_virginia_after(df, "COVERED", treat_by_year_after)
calculate_cov_virginia_after(df, "MALE", treat_by_year_after)
calculate_cov_virginia_after(df, "HIGHER_BAC", treat_by_year_after)
calculate_cov_virginia_after(df, "PRIVATE", treat_by_year_after)
calculate_cov_virginia_after(df, "POOREST", treat_by_year_after)
calculate_cov_virginia_after(df, "WHITE", treat_by_year_after)
calculate_cov_virginia_after(df, "OTHER_ETHNICITY", treat_by_year_after)
#Income's descriptive statistics
inc1 = mean(df$INCOME[df$YEAR == 2017 & df$VIRGINIA == 1], na.rm = TRUE)
inc2 = mean(df$INCOME[df$YEAR == 2018 & df$VIRGINIA == 1], na.rm = TRUE)
inc3 = mean(df$INCOME[df$YEAR == 2019 & df$VIRGINIA == 1], na.rm = TRUE)
inc4 = mean(df$INCOME[df$YEAR == 2020 & df$VIRGINIA == 1], na.rm = TRUE)
inc5 = mean(df$INCOME[df$YEAR == 2021 & df$VIRGINIA == 1], na.rm = TRUE)
inc6 = mean(df$INCOME[df$YEAR == 2022 & df$VIRGINIA == 1], na.rm = TRUE)
inc7 = mean(df$INCOME[df$YEAR == 2023 & df$VIRGINIA == 1], na.rm = TRUE)
inc8 = mean(df$INCOME[df$YEAR == 2024 & df$VIRGINIA == 1], na.rm = TRUE)
sum(inc1, inc2)/2
min(inc1, inc2)
max(inc1, inc2)
sd(c(inc1, inc2))
sum(inc3,inc4,inc5,inc6,inc7,inc8)/6
min(inc3,inc4,inc5,inc6,inc7,inc8)
max(inc3,inc4,inc5,inc6,inc7,inc8)
sd(c(inc3,inc4,inc5,inc6,inc7,inc8))
###############################################################################################
#In South Carolina
#Again we repeat the procedure for South Carolina
#Number of individuals for each Year in South Carolina
no_treat_2017 = sum(df$YEAR == 2017 & df$VIRGINIA == 0)
no_treat_2018 = sum(df$YEAR == 2018 & df$VIRGINIA == 0)
no_treat_2019 = sum(df$YEAR == 2019 & df$VIRGINIA == 0)
no_treat_2020 = sum(df$YEAR == 2020 & df$VIRGINIA == 0)
no_treat_2022 = sum(df$YEAR == 2022 & df$VIRGINIA == 0)
no_treat_2023 = sum(df$YEAR == 2023 & df$VIRGINIA == 0)
no_treat_2024 = sum(df$YEAR == 2024 & df$VIRGINIA == 0)
no_treat_2021 = sum(df$YEAR == 2021 & df$VIRGINIA == 0)
#Creation of a list for post-treatment and pre-treatment years
treat_by_year_before_treat <- list(
"2017" = no_treat_2017,
"2018" = no_treat_2018)
treat_by_year_after_treat <- list(
"2019" = no_treat_2019,
"2020" = no_treat_2020,
"2021" = no_treat_2021,
"2022" = no_treat_2022,
"2023" = no_treat_2023,
"2024" = no_treat_2024)
#Creation of two functions that compute the minimum, maximum, standard deviantion and mean values for post-treatment and pre-treatment periods in Virginia for a specific variable
#First for pre-treatment periods
calculate_cov_south_before <- function(data, var_name, treat_values) {
years <- 2017:2018
cov_values <- sapply(years, function(year) {
sum(data$YEAR == year & data$VIRGINIA == 0 & data[[var_name]] == 1) / treat_values[[as.character(year)]]
})
# Mean
mean_cov <- mean(cov_values, na.rm = TRUE)
# Minimum
min_cov <- min(cov_values, na.rm = TRUE)
# Maximum
max_cov <- max(cov_values, na.rm = TRUE)
# Standard deviation
sd_cov <-  sd(cov_values, na.rm = TRUE)
return(list(mean = mean_cov, min = min_cov, max = max_cov, sd = sd_cov))
}
#Secondly post-treatments periods
calculate_cov_south_after <- function(data, var_name, treat_values) {
years <- 2019:2024
cov_values <- sapply(years, function(year) {
sum(data$YEAR == year & data$VIRGINIA == 0 & data[[var_name]] == 1) / treat_values[[as.character(year)]]
})
# Mean
mean_cov <- mean(cov_values, na.rm = TRUE)
# Minimum
min_cov <- min(cov_values, na.rm = TRUE)
# Maximum
max_cov <- max(cov_values, na.rm = TRUE)
# Standard deviation
sd_cov <-  sd(cov_values, na.rm = TRUE)
return(list(mean = mean_cov, min = min_cov, max = max_cov, sd = sd_cov))
}
#Number of people each year in each state
mean = sum(no_treat_2017, no_treat_2018)/ 2
mean
min(no_treat_2017, no_treat_2018)
max(no_treat_2017, no_treat_2018)
sd(c(no_treat_2017, no_treat_2018))
mean = sum(no_treat_2019, no_treat_2020, no_treat_2022,
no_treat_2023, no_treat_2024, no_treat_2021 )/ 6
mean
min(no_treat_2019, no_treat_2020, no_treat_2022,
no_treat_2023, no_treat_2024, no_treat_2021 )
max(no_treat_2019, no_treat_2020, no_treat_2022,
no_treat_2023, no_treat_2024, no_treat_2021 )
sd(c(no_treat_2019, no_treat_2020, no_treat_2022,
no_treat_2023, no_treat_2024, no_treat_2021))
#Computation of the descriptive statistics for each variable, post and pre-treatment
calculate_cov_south_before(df, "COVERED", treat_by_year_before)
calculate_cov_south_before(df, "MALE", treat_by_year_before)
calculate_cov_south_before(df, "HIGHER_BAC", treat_by_year_before)
calculate_cov_south_before(df, "PRIVATE", treat_by_year_before)
calculate_cov_south_before(df, "POOREST", treat_by_year_before)
calculate_cov_south_before(df, "WHITE", treat_by_year_before)
calculate_cov_south_before(df, "OTHER_ETHNICITY", treat_by_year_before)
calculate_cov_south_after(df, "COVERED", treat_by_year_after)
calculate_cov_south_after(df, "MALE", treat_by_year_after)
calculate_cov_south_after(df, "HIGHER_BAC", treat_by_year_after)
calculate_cov_south_after(df, "PRIVATE", treat_by_year_after)
calculate_cov_south_after(df, "POOREST", treat_by_year_after)
calculate_cov_south_after(df, "WHITE", treat_by_year_after)
calculate_cov_south_after(df, "OTHER_ETHNICITY", treat_by_year_after)
#Income's descriptive statistics
inc12 = mean(df$INCOME[df$YEAR == 2017 & df$VIRGINIA == 0], na.rm = TRUE)
inc22 = mean(df$INCOME[df$YEAR == 2018 & df$VIRGINIA == 0], na.rm = TRUE)
inc32 = mean(df$INCOME[df$YEAR == 2019 & df$VIRGINIA == 0], na.rm = TRUE)
inc42 = mean(df$INCOME[df$YEAR == 2020 & df$VIRGINIA == 0], na.rm = TRUE)
inc52 = mean(df$INCOME[df$YEAR == 2021 & df$VIRGINIA == 0], na.rm = TRUE)
inc62 = mean(df$INCOME[df$YEAR == 2022 & df$VIRGINIA == 0], na.rm = TRUE)
inc72 = mean(df$INCOME[df$YEAR == 2023 & df$VIRGINIA == 0], na.rm = TRUE)
inc82 = mean(df$INCOME[df$YEAR == 2024 & df$VIRGINIA == 0], na.rm = TRUE)
sum(inc12, inc22)/2
min(inc12, inc22)
max(inc12, inc22)
sd(c(inc12, inc22))
sum(inc32,inc42,inc52,inc62,inc72,inc82)/6
min(inc32,inc42,inc52,inc62,inc72,inc82)
max(inc32,inc42,inc52,inc62,inc72,inc82)
sd(c(inc32,inc42,inc52,inc62,inc72,inc82))
sink("quarto_log9.txt")
var_pers <- c("HOUSEHOLD_ID", "COVERED", "COV_LY", "PRIVATE", "AGE", "INCOME", "POVERTY_LEVEL", "MEDICAID", "YEAR", "SEX", "EDUC", "WORK", "FIPS", "ETHNICITY")
table_1 <- data.frame(
Variable = var_pers,
Label = c("Household sequence number",
"Currently covered by health insurance",
"Any health insurance coverage last year",
"Covered by private insurance",
"Age of the individual",
"Total personal income",
"Poverty level category",
"Current Medicaid coverage",
"Survey year",
"Gender Indicator",
"Educational attainment",
"Employment classification",
"FIPS State Indicator",
"Ethnicity of the individual"),
Selection = c("", "", "", "", "19-64", "", "1,2 and 3 (individual between 0 and 150% of the federal poverty level)", "", "2017-2024", "", "", "", "45 (South Carolina) or 51 (Virginia)", "")
)
# Export to LaTeX
output_path_table1 <- file.path(base_dir, "Code", "Output", "Table_A1_Specification_and_Selection_of_CPS-ASEC_variables.tex")
# Generating Latex code
latex_code_1 <- print(xtable(table_1, type = "latex"), include.rownames = FALSE)
# Exporting results
writeLines(latex_code_1, output_path_table1)
sink("quarto_log10.txt")
# Creation of Table 2: Transformation of variables for analysis
table_2 <- data.frame(
Variable = c("COVERED", "", "MEDICAID", "", "PRIVATE", "", "MALE", "", "SUP2019", "", "HIGHER_BAC", "", "TREAT", "", "POOREST", "", "WHITE", "", "OTHER_ETHNICITY", ""),
Label = c("Currently covered by health insurance", "",
"Currently covered by Medicaid", "",
"Covered by private insurance", "",
"Indicator for gender", "",
"Indicator for before/after expansion", "",
"Indicator if the individual has at least a Highschool diploma", "",
"Indicator for treatment", "",
"Indicator for poverty level", "",
"Indicator for White ethnicity", "",
"Indicator for non-White ethnicity", ""),
Value = c("Not covered", "Covered",
"Not covered", "Covered",
"Not covered", "Covered",
"Female", "Male",
"Before expansion", "After expansion",
"Lower than highschool diploma", "At least high school diploma",
"Control or not treated yet", "Treated",
"Between 125% and 150% of FPL", "Below 125% of FPL",
"Not White", "White",
"White", "Other Ethnicities"),
Code = c(0, 1,
0, 1,
0, 1,
0, 1,
0, 1,
0, 1,
0, 1,
0, 1,
0, 1,
0, 1)
)
# Define the output file path
output_path_table2 <- file.path(base_dir, "Code", "Output", "Table_A2_Transformation_of_CPS-ASEC_variables.tex")
# Generate LaTeX code from the table
latex_code_2 <- print(xtable(table_2, type = "latex"), include.rownames = FALSE)
# Write the LaTeX table to a file
writeLines(latex_code_2, output_path_table2)
sink("quarto_log11.txt")
# Import the (clean) data set
df <- read_csv(output_path_bdd)
sink("quarto_log12.txt")
# Calculate the proportion of covered individuals by state and year
cov_trends <- df %>%
group_by(YEAR, VIRGINIA) %>%
summarise(cov_rate = mean(COVERED == 1, na.rm = TRUE), .groups = "drop")
# Plot the graph, we use the package ggplot2 to create the graph
ggplot(cov_trends, aes(x = YEAR, y = cov_rate, color = as.factor(VIRGINIA))) +
geom_line() +
geom_vline(xintercept = 2019, linetype = "dashed", color = "red") +  # Vertical line for the treatment year
labs(x = "Year", y = "Proportion of individuals with any type of coverage", color = "State") +
scale_color_manual(values = c("0" = "blue", "1" = "red"),
labels = c("0" = "South Carolina", "1" = "Virginia"),
name = "States") +
theme_minimal()
sink("quarto_log13.txt")
# Calculate the proportion of individuals with private insurance by state and year
priv_trends <- df %>%
group_by(YEAR, VIRGINIA) %>%
summarise(priv_rate = mean(PRIVATE == 1, na.rm = TRUE), .groups = "drop")
# Plot the graph
# Plot the graph, we use the package ggplot2 to create the graph
ggplot(priv_trends, aes(x = YEAR, y = priv_rate, color = as.factor(VIRGINIA))) +
geom_line() +
geom_vline(xintercept = 2019, linetype = "dashed", color = "red") +  # Vertical line for the treatment year
labs(x = "Year", y = "Proportion of individual with private insurance", color = "State") +
scale_color_manual(values = c("0" = "blue", "1" = "red"),
labels = c("0" = "South Carolina", "1" = "Virginia"),
name = "States") +
theme_minimal()
sink("quarto_log14.txt")
#To proceed, we use the function glm, doing a regression using a probit of COVERED on our explained variables
logit_model_COVERED <- glm(COVERED ~ SUP2019 + VIRGINIA + TREAT, data=df, family = binomial(link="probit"))
summary(logit_model_COVERED)
#This command allows to compute the average marginal effects of being in Virginia in the post period treatment on the private insurance's rate
avg_slopes(logit_model_COVERED)
sink("quarto_log15.txt")
#To proceed, we use the function glm, doing a regression using a probit of PRIVATE on our explained variables
logit_model_PRIVATE <- glm(PRIVATE ~ SUP2019 + VIRGINIA + TREAT, data=df, family = binomial(link="probit"))
summary(logit_model_PRIVATE)
#This command allows to compute the average marginal effects of being in Virginia in the post period treatment on the coverage's rate
avg_slopes(logit_model_PRIVATE)
sink("quarto_log16.txt")
# treatment_year
year_treatment <- 2019
# Converting Year in a numeric variable
df <- df %>%
mutate(YEAR = as.numeric(YEAR),
year = YEAR)
# We create temporal variables taking values t-2019 where 2019 is the treatment year
df <- df %>%
mutate(
time_to_treat = year - year_treatment, # Number of years pre/post treatment
treat_time = as.factor(time_to_treat)) # Categorical Variable
df <- df %>%
mutate(
Tm2 = ifelse(time_to_treat == -2, 1, 0),
Tm1 = ifelse(time_to_treat == -1, 1, 0),
)
#We create variables taking the value Tm1 or Tm2 if and only if the observation is in Virginia
df$TREAT_Tm2 = df$Tm2 * df$VIRGINIA
df$TREAT_Tm1 = df$Tm1 * df$VIRGINIA
#A placebo test, which is a logit model, is useful to verify the parallel trends assumption
#between the control and treatment groups. If the estimators are not significants, we can assume parallel trends
logit_placebo_test_on_covered = glm(COVERED~ SUP2019 + TREAT_Tm2 + TREAT_Tm1
, data=df, family = binomial(link="probit") )
summary(logit_placebo_test_on_covered)
logit_placebo_test_on_private = glm(PRIVATE~ SUP2019 + TREAT_Tm2 + TREAT_Tm1
, data=df, family = binomial(link="probit") )
summary(logit_placebo_test_on_private)
sink("quarto_log17.txt")
# We filter our data to extract age for each state before the expansion
age_virginia <- df$AGE[df$VIRGINIA == 1 & df$SUP2019 == 0]
age_south_carolina <- df$AGE[df$VIRGINIA == 0 & df$SUP2019 == 0]
# We check for summary statistics within each group
summary(age_virginia)
summary(age_south_carolina)
# We check for the normality assumption of the distribution of our variables (Shapiro-Wilk test (1965) for a sample size < 5000)
shapiro.test(age_virginia)
shapiro.test(age_south_carolina)
# We check for the equality of the variances of our variables within each group (Fisher test)
var.test(age_virginia, age_south_carolina)
# Running the Student t-test
t_test_result <- t.test(age_virginia, age_south_carolina, var.equal = FALSE)
print(t_test_result) # p-value = 0.03488
# We filter our data to extract INCOME for each state before the expansion
income_virginia <- df$INCOME[df$VIRGINIA == 1 & df$SUP2019 == 0]
income_south_carolina <- df$INCOME[df$VIRGINIA == 0 & df$SUP2019 == 0]
# We check for summary statistics within each group
summary(income_virginia)
summary(income_south_carolina)
# We check for the normality assumption of the distribution of our variables (Shapiro-Wilk test (1965) for a sample size < 5000)
shapiro.test(income_virginia)
shapiro.test(income_south_carolina)
# We check for the equality of the variances of our variables within each group (Fisher test)
var.test(income_virginia, income_south_carolina)
# Running the Student t-test
t_test_result <- t.test(income_virginia, income_south_carolina, var.equal = FALSE)
print(t_test_result) # p-value = 0.1951
# We create a contingency table of MALE by VIRGINIA
male_contingency_table <- table(df_balancing$MALE, df_balancing$VIRGINIA)
sink("quarto_log17.txt")
# We filter our data to extract age for each state before the expansion
age_virginia <- df$AGE[df$VIRGINIA == 1 & df$SUP2019 == 0]
age_south_carolina <- df$AGE[df$VIRGINIA == 0 & df$SUP2019 == 0]
# We check for summary statistics within each group
summary(age_virginia)
summary(age_south_carolina)
# We check for the normality assumption of the distribution of our variables (Shapiro-Wilk test (1965) for a sample size < 5000)
shapiro.test(age_virginia)
shapiro.test(age_south_carolina)
# We check for the equality of the variances of our variables within each group (Fisher test)
var.test(age_virginia, age_south_carolina)
# Running the Student t-test
t_test_result <- t.test(age_virginia, age_south_carolina, var.equal = FALSE)
print(t_test_result) # p-value = 0.03488
# We filter our data to extract INCOME for each state before the expansion
income_virginia <- df$INCOME[df$VIRGINIA == 1 & df$SUP2019 == 0]
income_south_carolina <- df$INCOME[df$VIRGINIA == 0 & df$SUP2019 == 0]
# We check for summary statistics within each group
summary(income_virginia)
summary(income_south_carolina)
# We check for the normality assumption of the distribution of our variables (Shapiro-Wilk test (1965) for a sample size < 5000)
shapiro.test(income_virginia)
shapiro.test(income_south_carolina)
# We check for the equality of the variances of our variables within each group (Fisher test)
var.test(income_virginia, income_south_carolina)
# Running the Student t-test
t_test_result <- t.test(income_virginia, income_south_carolina, var.equal = FALSE)
print(t_test_result) # p-value = 0.1951
# BALANCING TEST FOR MALE
df_balancing <- df[df$SUP2019 == 0, ] #Create the dataframe for balancing test
# We create a contingency table of MALE by VIRGINIA
male_contingency_table <- table(df_balancing$MALE, df_balancing$VIRGINIA)
print(male_contingency_table)
# Running the Chi-squared test
chi2_test_result <- chisq.test(male_contingency_table)
print(chi2_test_result) # p-value = 0.2653
# We create a contingency table of WHITE by VIRGINIA
white_contingency_table <- table(df_balancing$WHITE, df_balancing$VIRGINIA)
print(white_contingency_table)
# Running the Chi-squared test
chi2_test_result <- chisq.test(white_contingency_table)
print(chi2_test_result) # p-value = 0.0007209
# We create a contingency table of OTHER_ETHNICITY by VIRGINIA
other_ethnicity_contingency_table <- table(df_balancing$OTHER_ETHNICITY, df_balancing$VIRGINIA)
print(other_ethnicity_contingency_table)
# Running the Chi-squared test
chi2_test_result <- chisq.test(other_ethnicity_contingency_table)
print(chi2_test_result) # p-value = 0.0007209
df_balancing <- df[df$SUP2019 == 0, ] #Create the dataframe for balancing test
# For MASTER
balancing_educ2 <- glm( HIGHER_BAC  ~ VIRGINIA, data = df_balancing, family = binomial(link="probit"))
sink("quarto_log18.txt")
df_balancing <- df[df$SUP2019 == 0, ] #Create the dataframe for balancing test
# For MASTER
balancing_educ2 <- glm( HIGHER_BAC  ~ VIRGINIA, data = df_balancing, family = binomial(link="probit"))
summary(balancing_educ2)
# For AGE
balancing_age <- lm(AGE ~  VIRGINIA  , data = df_balancing)
summary(balancing_age)
# For MALE
balancing_male <- glm(MALE ~  VIRGINIA , data = df_balancing, family = binomial(link="probit"))
summary(balancing_male)
# For POOREST
balancing_poorest <- glm(POOREST ~ VIRGINIA, data = df_balancing, family = binomial(link="probit"))
summary(balancing_poorest)
# For WHITE
balancing_white <- glm(WHITE ~  VIRGINIA , data = df_balancing, family = binomial(link="probit"))
summary(balancing_white)
# For OTHER_ETHNICICITY
balancing_other_ethnicity <- glm(OTHER_ETHNICITY ~   VIRGINIA, data = df_balancing, family = binomial(link="probit"))
summary(balancing_other_ethnicity)
sink("quarto_log19.txt")
sink("quarto_log19.txt")
#To proceed, we use the function glm, doing a regression using a probit of COVERED on our explained variables
logit_model_COVERED_with_covariates <- glm(COVERED ~ AGE + WHITE + VIRGINIA + SUP2019 + TREAT, data=df, family = binomial(link="probit"))
summary(logit_model_COVERED_with_covariates)
